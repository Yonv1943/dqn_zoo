# Related Papers

* DQN

  [Playing Atari with Deep Reinforcement Learning](https://arxiv.org/abs/1312.5602)

* DDQN

  [Deep Reinforcement Learning with Double Q-learning](http://arxiv.org/abs/1509.06461)

* Dueling DQN

  [Dueling Network Architectures for Deep Reinforcement Learning](http://arxiv.org/abs/1511.06581)

* PER

  [Prioritized Experience Replay](http://arxiv.org/abs/1511.05952)

* Noisy DQN

  [Noisy Networks for Exploration](http://arxiv.org/abs/1706.10295)

* C51

  [A Distributional Perspective on Reinforcement Learning](http://arxiv.org/abs/1707.06887)

* QR DQN

  [Distributional Reinforcement Learning with Quantile Regression](https://arxiv.org/abs/1710.10044v1)

* IQN

  [Implicit Quantile Networks for Distributional Reinforcement Learning](http://arxiv.org/abs/1806.06923)

* FQF

  [Fully Parameterized Quantile Function for Distributional Reinforcement Learning](http://arxiv.org/abs/1911.02140)

* H-DQN

  [Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation](https://arxiv.org/abs/1604.06057v2)

* Rainbow

  [Rainbow: Combining Improvements in Deep Reinforcement Learning](http://arxiv.org/abs/1710.02298)

* MoG DQN

  [Distributional Deep Reinforcement Learning with a Mixture of Gaussians](https://ieeexplore.ieee.org/document/8793505/)

* NDQFN

  [Non-decreasing Quantile Function Network with Efficient Exploration for Distributional Reinforcement Learning](https://openreview.net/forum?id=f_GA2IU9-K-)

* Averaged DQN

  [Averaged-DQN: Variance Reduction and Stabilization for Deep Reinforcement Learning](http://arxiv.org/abs/1611.01929)